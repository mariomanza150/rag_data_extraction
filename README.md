
# RAG Data extraction LLM Project

## Objective

The aim of this project is to extract a series of data points, as specified in `data_points_manual_extract.csv`.

## Process Overview

1. **Document Processing**: Documents located in the `/data` folder are processed to extract text and load it as embeddings. This process is defined in `embedding_loader.py`.

2. **Prompting**: The prompting mechanism is outlined using the COSTAR framework. For a quick overview, refer to this [guide](https://medium.com/@frugalzentennial/unlocking-the-power-of-costar-prompt-engineering-a-guide-and-example-on-converting-goals-into-dc5751ce9875) or the [detailed version](https://www.developer.tech.gov.sg/products/collections/data-science-and-artificial-intelligence/playbooks/prompt-engineering-playbook-beta-v3.pdf).

## Prompting Details

### Master Prompt

The _master_ prompt, serving as a template for generating final prompts, is defined in the `QUESTION_TEMPLATE` within `llm_manager.py`. 

### Datapoint Prompts

Each data point is configured in `config_prompts.json` with the following structure:

\`\`\`json
{
    "section": "the section in which the datapoint is expected to be",
    "slug_name": "a slug_like name for the datapoint",
    "search": "a series of keywords or sentences for embedding search",
    "question": "a question form to aid in extrapolating the datapoint",
    "desc": "a short description of the datapoint"
}
\`\`\`

- **Search Field**: Defined as a comma-separated list of keywords or sentences. Use a '/' to enable multiple searches, e.g., `keyword,sen ten ce/keyword,sen ten ce/keyword`.

### Prompt Configuration Files

- `config_prompts_org.json`: Contains the original list of data points.
- `config_prompts_final.json`: Contains the prompts yielding the best results.
- `config_prompts.json`: The file used for prompt generation.

### Prompt Generation Process

Prompts are generated by injecting data point queries and embedding results text into the master prompt. This process is handled by the `create_prompt` function in `orchestrator.py`.

## Project Configuration

- **Expected responses**: Defined in `datapoint_extract.csv`. must have a `slug_name` and valid filename, that matches the filename in `expected_filename` in def `run_dp_inference` in `orchestrator.py`.
- **Model Configuration**: Defined in `config_model.json`. Set the `base_url` and `apikey` parameters here.
- **Embedding and Vector Store Configuration**: Defined in `main.py`.
- **Process Flags**: Various flags for selecting processes to execute are defined in `main.py`.

- **Start Point**: Run python `main.py`, configure steps inside
